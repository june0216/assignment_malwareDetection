{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Si8y808g1T7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier # 탐지 모델은 randomforest로 선택\n",
        "from sklearn.model_selection import train_test_split \n",
        "from imblearn.over_sampling import SMOTE \n",
        "from sklearn import preprocessing \n",
        "import gc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8qEpEOqRCsB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab8fc9a6-2a58-48d9-89c1-f83d9f491c63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8efD_m7a71c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f33ef8-b745-41f6-dc68-cfabde16ab74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['network_benign_training_set_00.csv',\n",
              " 'network_benign_training_set_01.csv',\n",
              " 'network_benign_training_set_02.csv',\n",
              " 'network_benign_training_set_03.csv',\n",
              " 'network_benign_training_set_04.csv',\n",
              " 'network_benign_training_set_05.csv',\n",
              " 'network_benign_training_set_06.csv',\n",
              " 'network_benign_training_set_07.csv',\n",
              " 'network_benign_training_set_10.csv',\n",
              " 'network_benign_training_set_09.csv',\n",
              " 'network_benign_training_set_08.csv',\n",
              " 'network_benign_training_set_11.csv',\n",
              " 'network_benign_training_set_12.csv',\n",
              " 'network_benign_training_set_13.csv',\n",
              " 'network_benign_training_set_14.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "os.listdir('./drive/MyDrive/network_benign_training_set') # 드라이브 내 csv 파일을 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KecDgM7dbX1i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86d66f53-5279-4afc-b6f2-0d782acdf365"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "base_src = './drive/MyDrive/network_benign_training_set' #benign_training_set 파일 내에 14개의 benign_training set 14개의 파일이 있음\n",
        "\n",
        "set0_src = base_src+\"/network_benign_training_set_00.csv\" #먼저 첫번째 benign_training set 파일을 선택\n",
        "\n",
        "\n",
        "benign_data=pd.read_csv(set0_src, dtype='object', usecols=[1,2,3,4,5,6,7,8]) #첫 번째 benign_training set 파일을 읽어옴\n",
        "#이때, 같은 컬럼에 다양한 타입이 있어서 한 번에 object 타입으로 불러옴 , 그리고 usecols로 원하는 데이터(열)만 불러옴 , 이 열들을 고른 기준은 malicious data는 TCP FTP로 구성되어 있기 때문에 정확한 학습을 위해 udp 관련 열와 http 관련 열은 제외했다. \n",
        "\n",
        "for i in range(1, 15): #나머지 benign_training set 중 1 ~ 14까지의 파일들을 불러와서 덧붙임\n",
        "  if(int(i/10) > 0): #파일 번호가 10의 자리 숫자일 때, 1의 자리 숫자일 때 전자는 문자 전체로, 후자는 앞자리에 0이 붙으므로 경우의 수를 나누어 파일 명을 만듦\n",
        "    temp =  base_src+\"/network_benign_training_set_\"+str(i)+\".csv\"\n",
        "  else:\n",
        "    temp =  base_src+\"/network_benign_training_set_0\"+str(i)+\".csv\"\n",
        "\n",
        "  t=pd.read_csv(temp, dtype='object', usecols=[1,2,3,4,5,6,7,8]) # 각 파일을 순서대로 불러오되, usecols로 원하는 데이터(열)만 불러온다. \n",
        "\n",
        "  benign_data=pd.concat([benign_data,t]) #앞에 불러온 파일의 뒤에 새로 불러온 파일을 붙인다. \n",
        "\n",
        "malicious_data=pd.read_csv('./drive/MyDrive/network_malicious_training_set.csv', dtype='object', usecols=[1,2,3,4,5,6,7,8])\n",
        "#malicious_data를 따로 드라이브에서 불러온다. 이때, usecols로 원하는 데이터(열)만 불러온다. \n",
        "\n",
        "benign_data=benign_data.fillna('') #Nan(=표현할 수 없는 값)으로 나타나는 입력값들을 빈값으로 변경한다. \n",
        "total=benign_data #benign \n",
        "benign_len=len(benign_data)# 데이터에 대한 라벨링(악성인지 아닌지)을 하기 위해 길이를 활용\n",
        "del benign_data #이제 benign_data는 필요없는 데이터이므로 메모리에서 삭제 \n",
        "malicious_data=malicious_data.fillna('')#Nan(=표현할 수 없는 값)으로 나타나는 입력값들을 빈값으로 변경한다. \n",
        "\n",
        "total=pd.concat([total, malicious_data]) #앞에서 benign를 복사한 변수인 total 과 malicious의 데이터를 한 번에 같이 저장하여 model을 훈련해야 하므로 total 변수에 합친다. \n",
        "\n",
        "malicious_len = len(malicious_data)# 데이터에 대한 라벨링(악성인지 아닌지)을 하기 위해 길이를 활용\n",
        "del malicious_data #이제 malicious_data는 필요없는 데이터이므로 메모리에서 삭제 \n",
        "\n",
        "\n",
        "le=preprocessing.LabelEncoder() #각 컬럼들을 수치형 데이터로 변환했다.\n",
        "total[\"_ws.col.Protocol\"]=le.fit_transform(total[\"_ws.col.Protocol\"]) \n",
        "pd.get_dummies(total['_ws.col.Protocol']) #범주형 데이터를 가변수화\n",
        "total[\"ip.src\"]=le.fit_transform(total[\"ip.src\"])\n",
        "total[\"ip.dst\"]=le.fit_transform(total[\"ip.dst\"])\n",
        "total[\"tcp.srcport\"]=le.fit_transform(total[\"tcp.srcport\"])\n",
        "total[\"tcp.dstport\"]=le.fit_transform(total[\"tcp.dstport\"])\n",
        "total[\"tcp.len\"]=le.fit_transform(total[\"tcp.len\"])\n",
        "total[\"tcp.seq\"]=le.fit_transform(total[\"tcp.seq\"])\n",
        "total[\"tcp.ack\"]=le.fit_transform(total[\"tcp.ack\"])\n",
        "\n",
        "\n",
        "\n",
        "y = np.hstack([np.zeros(benign_len), np.ones(malicious_len)])#라벨 데이터 만들기(행의 개수 만큼 0 = 정상, 1 = 악성)\n",
        "sm = SMOTE(sampling_strategy='auto', random_state=0) #악성 샘플 데이터와 benign 데이터 양의 차이가 매우 크므로 정확한 모델을 훈련하기 위해 smote을 사용\n",
        "\n",
        "\n",
        "\n",
        "#test에 활용할 데이터와 실제 검증할 테스트를 나눠주는 과정 이때, 적절하다고 알려진 비율인 0.25으로 설정\n",
        "total_train, total_valid, y_train, y_valid = train_test_split(total, y, test_size=0.25, shuffle=True, stratify=y, random_state=0)\n",
        "\n",
        "total_samp, y_samp=sm.fit_resample(total_train, y_train)#smote를 통한 데이터 불균형 조절은 train 데이터만 해야 하므로 train set만 조절함\n",
        "\n",
        "del total_train #이제 필요없는 변수들을 메모리에서 삭제한다. \n",
        "del y_train\n",
        "del total\n",
        "\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcXPSA_wcQg6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hr5m9UYgmll9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d645fec5-3526-475f-d185-617cdac5b9a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9791118497265467\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score # 정확도 함수\n",
        "\n",
        "#model = RandomForestClassifier(n_estimators=10, max_depth=4 , criterion='entropy', random_state=0) #n_estimators => 트리의 개수, \n",
        "model = RandomForestClassifier(n_estimators=20, max_depth=4 , criterion='entropy', random_state=0)\n",
        "model.fit(total_samp, y_samp)\n",
        "\n",
        "#RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
        " #                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
        "  #                     min_impurity_decrease=0.0, \n",
        "   #                    min_samples_leaf=1, min_samples_split=2,\n",
        "    #                   min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "     #                  n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
        "      #                 warm_start=False)\n",
        "\n",
        "predict1 = model.predict(total_valid)\n",
        "print(accuracy_score(y_valid,predict1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_origin=pd.read_csv('./drive/MyDrive/network_test_dataset.csv', dtype='object', header=None,names=['_ws.col.Protocol','ip.src','ip.dst', 'tcp.srcport', 'tcp.dstport', 'tcp.len', 'tcp.seq', 'tcp.ack',], usecols=[1,2,3,4,5,6,7,8])\n",
        "\n",
        "test_data=test_data_origin.fillna('')\n",
        "le=preprocessing.LabelEncoder()\n",
        "print(len(test_data_origin))\n",
        "\n",
        "test_data['_ws.col.Protocol']=le.fit_transform(test_data['_ws.col.Protocol'])\n",
        "pd.get_dummies(test_data['_ws.col.Protocol'])\n",
        "test_data['ip.src']=le.fit_transform(test_data['ip.src'])\n",
        "test_data['ip.dst']=le.fit_transform(test_data['ip.dst'])\n",
        "test_data['tcp.srcport']=le.fit_transform(test_data['tcp.srcport'])\n",
        "test_data['tcp.dstport']=le.fit_transform(test_data['tcp.dstport'])\n",
        "test_data['tcp.len']=le.fit_transform(test_data['tcp.len'])\n",
        "test_data['tcp.seq']=le.fit_transform(test_data['tcp.seq'])\n",
        "test_data['tcp.ack']=le.fit_transform(test_data['tcp.ack'])\n",
        "\n",
        "predict1 = model.predict(test_data)\n",
        "for i in range(len(predict1)):\n",
        "  if predict1[i]==1:    \n",
        "    print(i)\n"
      ],
      "metadata": {
        "id": "fiBQLfs9uN6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f4d12d-8ca4-4726-f695-be6928d949f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3710834\n",
            "481205\n",
            "496149\n",
            "559996\n",
            "649741\n",
            "666983\n",
            "1336255\n",
            "1763833\n",
            "2478450\n",
            "2982954\n",
            "3388968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list = []\n",
        "for i in range(len(predict1)):\n",
        "  if predict1[i]==1:\n",
        "    list.append(i)\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mV_pT6WBaFbP",
        "outputId": "b6ded45e-54ed-48f8-a4d9-50fa5363f91e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481205\n",
            "496149\n",
            "559996\n",
            "649741\n",
            "666983\n",
            "1336255\n",
            "1763833\n",
            "2478450\n",
            "2982954\n",
            "3388968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pandas import DataFrame\n",
        "result_data=[[]]\n",
        "result_data = test_data_origin.iloc[[481205,496149,559996,649741,666983,1336255, 1763833, 2478450,2982954,3388968], :]\n",
        "result_df=DataFrame(result_data)\n",
        "\n",
        "\n",
        "result_df.to_csv(path_or_buf='./drive/MyDrive/'+'test1.csv')\n"
      ],
      "metadata": {
        "id": "OqNMi9LUjpiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyrmWpTD2X4a"
      },
      "outputs": [],
      "source": [
        "#RandomForest 사용 시 파라미터 튜닝을 통해 정확도를 높일 수 있다. \n",
        "#구글 코랩의 기본 계정 용량의 제한으로 인해 (ram 부족)시도를 해보지 못했지만 이런 방식으로 튜닝을 하면서 탐지의 정확도를 높일 수 있음 \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params= {'n_estimators':[10, 20, 30],\n",
        "         'max_depth':[10, 15, 20],\n",
        "         'max_leaf_nodes':[50, 100, 200],\n",
        "         'max_features':['auto', 'sqrt', 'log2']} #최고 성능의 파라미터를 찾기 위해 경우의 수들을 나열\n",
        "\n",
        "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
        "rf_clf = RandomForestClassifier(random_state = 0, n_jobs = -1)\n",
        "grid_cv = GridSearchCV(rf_clf, param_grid = params, cv = 10, n_jobs = -1)\n",
        "grid_cv.fit(total_samp, y_samp)\n",
        "\n",
        "print('최적 하이퍼 파라미터: ', grid_cv.best_params_)# 검사했던 params들 중 가장 최적인 파라미터를 출력 \n",
        "print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}